{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "data =\"\"\"Hi, my name is Sarah. I live in New York with my family. Every morning, I wake up at 7 a.m., brush my teeth, and make a cup of coffee. I usually have toast or cereal for breakfast. After that, I check my emails and get ready for work.\n",
        "\n",
        "I work as a graphic designer at a creative agency. I enjoy designing logos and creating illustrations. At lunch, I like to go out with my coworkers or sometimes eat at my desk. In the evenings, I go for a walk or read a book. On weekends, I enjoy visiting art galleries or watching movies.\n",
        "\n",
        "My best friend’s name is Jake. We’ve known each other since high school. We talk almost every day and often hang out on weekends. He loves playing video games and watching football.\n",
        "\n",
        "Sometimes I travel to other cities for work. Last month, I went to Chicago for a design conference. It was a great experience. I met many new people and learned about the latest design trends.\n",
        "\n",
        "I also enjoy cooking. My favorite dish to make is pasta with homemade tomato sauce. On Sundays, I usually cook a big meal and invite my friends over. We laugh, eat, and talk for hours.\n",
        "\n",
        "Life is busy, but I try to find time to relax and enjoy the small moments. I like writing in my journal before bed. It helps me reflect and stay positive.\n",
        "\n",
        "That’s a little bit about me.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "K22n-mSEIvwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "I0lvzXZCJK10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "URck0rZJJzzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([data])"
      ],
      "metadata": {
        "id": "y37lSHwUJ934"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hpDupdI3J_ru",
        "outputId": "d5f73de1-89af-458e-968f-adaaa0cbc9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'i': 1,\n",
              " 'my': 2,\n",
              " 'a': 3,\n",
              " 'and': 4,\n",
              " 'for': 5,\n",
              " 'to': 6,\n",
              " 'is': 7,\n",
              " 'at': 8,\n",
              " 'or': 9,\n",
              " 'enjoy': 10,\n",
              " 'in': 11,\n",
              " 'with': 12,\n",
              " 'work': 13,\n",
              " 'the': 14,\n",
              " 'on': 15,\n",
              " 'name': 16,\n",
              " 'new': 17,\n",
              " 'every': 18,\n",
              " 'make': 19,\n",
              " 'usually': 20,\n",
              " 'like': 21,\n",
              " 'go': 22,\n",
              " 'out': 23,\n",
              " 'sometimes': 24,\n",
              " 'eat': 25,\n",
              " 'weekends': 26,\n",
              " 'watching': 27,\n",
              " 'other': 28,\n",
              " 'we': 29,\n",
              " 'talk': 30,\n",
              " 'design': 31,\n",
              " 'it': 32,\n",
              " 'about': 33,\n",
              " 'me': 34,\n",
              " 'hi': 35,\n",
              " 'sarah': 36,\n",
              " 'live': 37,\n",
              " 'york': 38,\n",
              " 'family': 39,\n",
              " 'morning': 40,\n",
              " 'wake': 41,\n",
              " 'up': 42,\n",
              " '7': 43,\n",
              " 'm': 44,\n",
              " 'brush': 45,\n",
              " 'teeth': 46,\n",
              " 'cup': 47,\n",
              " 'of': 48,\n",
              " 'coffee': 49,\n",
              " 'have': 50,\n",
              " 'toast': 51,\n",
              " 'cereal': 52,\n",
              " 'breakfast': 53,\n",
              " 'after': 54,\n",
              " 'that': 55,\n",
              " 'check': 56,\n",
              " 'emails': 57,\n",
              " 'get': 58,\n",
              " 'ready': 59,\n",
              " 'as': 60,\n",
              " 'graphic': 61,\n",
              " 'designer': 62,\n",
              " 'creative': 63,\n",
              " 'agency': 64,\n",
              " 'designing': 65,\n",
              " 'logos': 66,\n",
              " 'creating': 67,\n",
              " 'illustrations': 68,\n",
              " 'lunch': 69,\n",
              " 'coworkers': 70,\n",
              " 'desk': 71,\n",
              " 'evenings': 72,\n",
              " 'walk': 73,\n",
              " 'read': 74,\n",
              " 'book': 75,\n",
              " 'visiting': 76,\n",
              " 'art': 77,\n",
              " 'galleries': 78,\n",
              " 'movies': 79,\n",
              " 'best': 80,\n",
              " 'friend’s': 81,\n",
              " 'jake': 82,\n",
              " 'we’ve': 83,\n",
              " 'known': 84,\n",
              " 'each': 85,\n",
              " 'since': 86,\n",
              " 'high': 87,\n",
              " 'school': 88,\n",
              " 'almost': 89,\n",
              " 'day': 90,\n",
              " 'often': 91,\n",
              " 'hang': 92,\n",
              " 'he': 93,\n",
              " 'loves': 94,\n",
              " 'playing': 95,\n",
              " 'video': 96,\n",
              " 'games': 97,\n",
              " 'football': 98,\n",
              " 'travel': 99,\n",
              " 'cities': 100,\n",
              " 'last': 101,\n",
              " 'month': 102,\n",
              " 'went': 103,\n",
              " 'chicago': 104,\n",
              " 'conference': 105,\n",
              " 'was': 106,\n",
              " 'great': 107,\n",
              " 'experience': 108,\n",
              " 'met': 109,\n",
              " 'many': 110,\n",
              " 'people': 111,\n",
              " 'learned': 112,\n",
              " 'latest': 113,\n",
              " 'trends': 114,\n",
              " 'also': 115,\n",
              " 'cooking': 116,\n",
              " 'favorite': 117,\n",
              " 'dish': 118,\n",
              " 'pasta': 119,\n",
              " 'homemade': 120,\n",
              " 'tomato': 121,\n",
              " 'sauce': 122,\n",
              " 'sundays': 123,\n",
              " 'cook': 124,\n",
              " 'big': 125,\n",
              " 'meal': 126,\n",
              " 'invite': 127,\n",
              " 'friends': 128,\n",
              " 'over': 129,\n",
              " 'laugh': 130,\n",
              " 'hours': 131,\n",
              " 'life': 132,\n",
              " 'busy': 133,\n",
              " 'but': 134,\n",
              " 'try': 135,\n",
              " 'find': 136,\n",
              " 'time': 137,\n",
              " 'relax': 138,\n",
              " 'small': 139,\n",
              " 'moments': 140,\n",
              " 'writing': 141,\n",
              " 'journal': 142,\n",
              " 'before': 143,\n",
              " 'bed': 144,\n",
              " 'helps': 145,\n",
              " 'reflect': 146,\n",
              " 'stay': 147,\n",
              " 'positive': 148,\n",
              " 'that’s': 149,\n",
              " 'little': 150,\n",
              " 'bit': 151}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "HOCmN0gZKDjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "input_sentence = []\n",
        "\n",
        "token_list = tokenizer.texts_to_sequences([data])[0]\n",
        "\n",
        "for i in range (1, len(token_list)):\n",
        "  n_gram_sequences = token_list[:i+1]\n",
        "  input_sentence.append(n_gram_sequences)\n",
        "\n"
      ],
      "metadata": {
        "id": "-Pv-RCSblex7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max([len(seq) for seq in input_sentence])\n",
        "input_sequences = pad_sequences(input_sentence, maxlen=max_sequence_len, padding='pre')"
      ],
      "metadata": {
        "id": "aWhD7OfLlpMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "input_sentence = np.array(input_sequences)\n",
        "\n",
        "x = input_sentence[:,:-1]\n",
        "y = input_sentence[:,-1]"
      ],
      "metadata": {
        "id": "YWHxNSTlmhoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
      ],
      "metadata": {
        "id": "w82rrgEZm4SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM, Dense"
      ],
      "metadata": {
        "id": "bW3tRgF2nDM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6YGEFzdns0n",
        "outputId": "1489dc8b-2b45-4c06-b0b7-022d45d590f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iiDqPh-loH3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x18FC8UoJyN",
        "outputId": "5aaf140e-c22f-4f29-80d2-41f753276e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 337ms/step - accuracy: 0.0118 - loss: 5.0238\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 301ms/step - accuracy: 0.0507 - loss: 4.9965\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.0534 - loss: 4.8151\n",
            "Epoch 4/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 478ms/step - accuracy: 0.0703 - loss: 4.7291\n",
            "Epoch 5/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 360ms/step - accuracy: 0.0664 - loss: 4.6635\n",
            "Epoch 6/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 310ms/step - accuracy: 0.0881 - loss: 4.6032\n",
            "Epoch 7/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 301ms/step - accuracy: 0.0471 - loss: 4.6706\n",
            "Epoch 8/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 426ms/step - accuracy: 0.0594 - loss: 4.6489\n",
            "Epoch 9/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 301ms/step - accuracy: 0.0643 - loss: 4.6443\n",
            "Epoch 10/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 308ms/step - accuracy: 0.0598 - loss: 4.6210\n",
            "Epoch 11/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 299ms/step - accuracy: 0.1045 - loss: 4.3969\n",
            "Epoch 12/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 456ms/step - accuracy: 0.1111 - loss: 4.4061\n",
            "Epoch 13/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 302ms/step - accuracy: 0.0986 - loss: 4.3116\n",
            "Epoch 14/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 300ms/step - accuracy: 0.0916 - loss: 4.2493\n",
            "Epoch 15/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 301ms/step - accuracy: 0.1098 - loss: 4.1218\n",
            "Epoch 16/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 500ms/step - accuracy: 0.1275 - loss: 3.8913\n",
            "Epoch 17/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 300ms/step - accuracy: 0.1345 - loss: 3.7372\n",
            "Epoch 18/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 302ms/step - accuracy: 0.1366 - loss: 3.5902\n",
            "Epoch 19/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 302ms/step - accuracy: 0.1812 - loss: 3.2816\n",
            "Epoch 20/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 469ms/step - accuracy: 0.1827 - loss: 3.2255\n",
            "Epoch 21/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 304ms/step - accuracy: 0.2417 - loss: 3.0055\n",
            "Epoch 22/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 309ms/step - accuracy: 0.2347 - loss: 2.8423\n",
            "Epoch 23/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 319ms/step - accuracy: 0.2211 - loss: 2.7344\n",
            "Epoch 24/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 302ms/step - accuracy: 0.2715 - loss: 2.5370\n",
            "Epoch 25/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 301ms/step - accuracy: 0.3309 - loss: 2.4325\n",
            "Epoch 26/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 290ms/step - accuracy: 0.3346 - loss: 2.3757\n",
            "Epoch 27/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 315ms/step - accuracy: 0.3976 - loss: 2.2491\n",
            "Epoch 28/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.4096 - loss: 2.1470\n",
            "Epoch 29/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 301ms/step - accuracy: 0.4574 - loss: 2.0263\n",
            "Epoch 30/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - accuracy: 0.5550 - loss: 1.9394\n",
            "Epoch 31/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 442ms/step - accuracy: 0.5552 - loss: 1.8782\n",
            "Epoch 32/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 305ms/step - accuracy: 0.6346 - loss: 1.7494\n",
            "Epoch 33/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 296ms/step - accuracy: 0.6505 - loss: 1.6745\n",
            "Epoch 34/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 315ms/step - accuracy: 0.6953 - loss: 1.6462\n",
            "Epoch 35/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 452ms/step - accuracy: 0.7178 - loss: 1.5748\n",
            "Epoch 36/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - accuracy: 0.7443 - loss: 1.4960\n",
            "Epoch 37/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - accuracy: 0.7947 - loss: 1.4377\n",
            "Epoch 38/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 313ms/step - accuracy: 0.8459 - loss: 1.3765\n",
            "Epoch 39/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 356ms/step - accuracy: 0.8594 - loss: 1.3142\n",
            "Epoch 40/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 321ms/step - accuracy: 0.8669 - loss: 1.2426\n",
            "Epoch 41/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 326ms/step - accuracy: 0.8748 - loss: 1.2120\n",
            "Epoch 42/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 487ms/step - accuracy: 0.9162 - loss: 1.1573\n",
            "Epoch 43/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 316ms/step - accuracy: 0.9265 - loss: 1.1214\n",
            "Epoch 44/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 313ms/step - accuracy: 0.9322 - loss: 1.0572\n",
            "Epoch 45/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.9370 - loss: 1.0223\n",
            "Epoch 46/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 320ms/step - accuracy: 0.9538 - loss: 1.0008\n",
            "Epoch 47/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 303ms/step - accuracy: 0.9541 - loss: 0.9345\n",
            "Epoch 48/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 311ms/step - accuracy: 0.9617 - loss: 0.8866\n",
            "Epoch 49/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 315ms/step - accuracy: 0.9693 - loss: 0.8918\n",
            "Epoch 50/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 406ms/step - accuracy: 0.9802 - loss: 0.8403\n",
            "Epoch 51/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 309ms/step - accuracy: 0.9857 - loss: 0.8030\n",
            "Epoch 52/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 465ms/step - accuracy: 0.9943 - loss: 0.7594\n",
            "Epoch 53/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 308ms/step - accuracy: 0.9889 - loss: 0.7395\n",
            "Epoch 54/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 308ms/step - accuracy: 0.9980 - loss: 0.7119\n",
            "Epoch 55/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 0.6770\n",
            "Epoch 56/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 300ms/step - accuracy: 0.9980 - loss: 0.6406\n",
            "Epoch 57/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 443ms/step - accuracy: 1.0000 - loss: 0.6106\n",
            "Epoch 58/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 0.6093\n",
            "Epoch 59/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 304ms/step - accuracy: 0.9991 - loss: 0.5842\n",
            "Epoch 60/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 0.5664\n",
            "Epoch 61/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 427ms/step - accuracy: 1.0000 - loss: 0.5345\n",
            "Epoch 62/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.5079\n",
            "Epoch 63/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.4984\n",
            "Epoch 64/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 0.4695\n",
            "Epoch 65/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.4688\n",
            "Epoch 66/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 297ms/step - accuracy: 1.0000 - loss: 0.4388\n",
            "Epoch 67/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 0.4253\n",
            "Epoch 68/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 0.4149\n",
            "Epoch 69/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 0.4107\n",
            "Epoch 70/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 0.3828\n",
            "Epoch 71/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 0.3783\n",
            "Epoch 72/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 0.3569\n",
            "Epoch 73/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 484ms/step - accuracy: 1.0000 - loss: 0.3580\n",
            "Epoch 74/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 0.3383\n",
            "Epoch 75/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 0.3123\n",
            "Epoch 76/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 0.3093\n",
            "Epoch 77/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 0.3053\n",
            "Epoch 78/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 0.2873\n",
            "Epoch 79/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 0.2732\n",
            "Epoch 80/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - accuracy: 1.0000 - loss: 0.2534\n",
            "Epoch 81/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 0.2692\n",
            "Epoch 82/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 0.2557\n",
            "Epoch 83/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 0.2379\n",
            "Epoch 84/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 0.2352\n",
            "Epoch 85/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 0.2250\n",
            "Epoch 86/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 0.2073\n",
            "Epoch 87/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 0.2065\n",
            "Epoch 88/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 472ms/step - accuracy: 1.0000 - loss: 0.2043\n",
            "Epoch 89/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 0.1940\n",
            "Epoch 90/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 0.1846\n",
            "Epoch 91/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.1867\n",
            "Epoch 92/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 0.1742\n",
            "Epoch 93/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 0.1709\n",
            "Epoch 94/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 0.1622\n",
            "Epoch 95/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 0.1656\n",
            "Epoch 96/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 0.1514\n",
            "Epoch 97/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.1543\n",
            "Epoch 98/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.1518\n",
            "Epoch 99/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.1410\n",
            "Epoch 100/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 452ms/step - accuracy: 1.0000 - loss: 0.1391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(seed_text, max_sequence_len):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "    predicted_probs = model.predict(token_list, verbose=0)\n",
        "    predicted_index = np.argmax(predicted_probs)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_index:\n",
        "            return word\n"
      ],
      "metadata": {
        "id": "XENU1HBBoOfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next_word(\"my name is\", max_sequence_len))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv8DGnWCqXi7",
        "outputId": "00627125-dba2-4b7b-9176-f9bb56163cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sarah\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentence(seed_text, next_words=10):\n",
        "    for _ in range(next_words):\n",
        "        next_word = predict_next_word(seed_text, max_sequence_len)\n",
        "        seed_text += \" \" + next_word\n",
        "    return seed_text\n",
        "\n",
        "print(generate_sentence(\"my name is \", next_words=10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7pGI5sCqZa9",
        "outputId": "990da493-869f-4ca8-d448-2502f1a9ea27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my name is  sarah i live in new york with my family every\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crc2WpsXqjzR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}